{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b568ea-114a-4d2e-8956-577746c73128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "C:\\Users\\harsh\\anaconda\\Lib\\inspect.py:1020: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_20484\\3706468728.py:8: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import SpeakerRecognition\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ ENROLLMENT ------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter and then speak your enrollment phrase for 7 seconds... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listening for speech...\n",
      "Enrollment complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "C:\\Users\\harsh\\anaconda\\Lib\\site-packages\\speechbrain\\utils\\autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "C:\\Users\\harsh\\anaconda\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
      "  warnings.warn(\n",
      "C:\\Users\\harsh\\anaconda\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 'enrolled_owner.wav' with 'v1.wav':\n",
      "  Similarity score: 0.0111 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v2.wav':\n",
      "  Similarity score: 0.0636 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v3.wav':\n",
      "  Similarity score: 0.1283 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v4.wav':\n",
      "  Similarity score: 0.0280 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v5.wav':\n",
      "  Similarity score: 0.0989 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v6.wav':\n",
      "  Similarity score: 0.1676 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v7.wav':\n",
      "  Similarity score: 0.0410 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v8.wav':\n",
      "  Similarity score: 0.0364 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v9.wav':\n",
      "  Similarity score: 0.0238 --> Prediction: No Match\n",
      "\n",
      "Comparing 'enrolled_owner.wav' with 'v10.wav':\n",
      "  Similarity score: 0.0910 --> Prediction: No Match\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing our audio with 10 audio\n",
    "\n",
    "import os\n",
    "import time\n",
    "import wave\n",
    "import webrtcvad\n",
    "import sounddevice as sd\n",
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "\n",
    "MODEL_PATH = \"pretrained_models/spkrec-ecapa-voxceleb\"\n",
    "ENROLLMENT_AUDIO_FILE = \"enrolled_owner.wav\"\n",
    "AUDIO_FS = 16000\n",
    "CHANNELS = 1\n",
    "FRAME_DURATION_MS = 30\n",
    "MAX_SILENCE_DURATION_SEC = 1.0\n",
    "ENROLL_DURATION = 7  # seconds\n",
    "\n",
    "def write_wave(path, audio_bytes, sample_rate):\n",
    "    with wave.open(path, 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(2)  # 16-bit PCM\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio_bytes)\n",
    "\n",
    "def record_audio_vad(duration_limit=10):\n",
    "    vad = webrtcvad.Vad(2)\n",
    "    frame_size = int(AUDIO_FS * FRAME_DURATION_MS / 1000)\n",
    "    silence_frames = 0\n",
    "    voiced_frames = bytearray()\n",
    "\n",
    "    print(\"\\nListening for speech...\")\n",
    "\n",
    "    stream = sd.InputStream(samplerate=AUDIO_FS, channels=CHANNELS, dtype='int16')\n",
    "    stream.start()\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        while True:\n",
    "            frame, _ = stream.read(frame_size)\n",
    "            frame_bytes = frame.tobytes()\n",
    "            is_speech = vad.is_speech(frame_bytes, AUDIO_FS)\n",
    "            if is_speech:\n",
    "                voiced_frames.extend(frame_bytes)\n",
    "                silence_frames = 0\n",
    "            else:\n",
    "                if voiced_frames:\n",
    "                    silence_frames += 1\n",
    "                    if (silence_frames * FRAME_DURATION_MS) / 1000 > MAX_SILENCE_DURATION_SEC:\n",
    "                        break\n",
    "            if time.time() - start_time > duration_limit:\n",
    "                break\n",
    "    finally:\n",
    "        stream.stop()\n",
    "        stream.close()\n",
    "\n",
    "    if not voiced_frames:\n",
    "        print(\"No speech detected.\")\n",
    "        return None\n",
    "    return bytes(voiced_frames)\n",
    "\n",
    "def enroll_owner():\n",
    "    print(f\"------ ENROLLMENT ------\")\n",
    "    input(f\"Press Enter and then speak your enrollment phrase for {ENROLL_DURATION} seconds...\")\n",
    "    audio_bytes = record_audio_vad(duration_limit=ENROLL_DURATION)\n",
    "    if not audio_bytes:\n",
    "        print(\"Enrollment failed: no speech detected.\")\n",
    "        return False\n",
    "    write_wave(ENROLLMENT_AUDIO_FILE, audio_bytes, AUDIO_FS)\n",
    "    print(\"Enrollment complete.\")\n",
    "    return True\n",
    "\n",
    "def verify_files(model, enrollment_file, test_file):\n",
    "    score, prediction = model.verify_files(enrollment_file, test_file)\n",
    "    pred_str = \"Match\" if prediction.item() else \"No Match\"\n",
    "    print(f\"Comparing '{enrollment_file}' with '{test_file}':\")\n",
    "    print(f\"  Similarity score: {score.item():.4f} --> Prediction: {pred_str}\")\n",
    "    print()\n",
    "\n",
    "def main():\n",
    "    # Step 1: Enroll your voice\n",
    "    if not enroll_owner():\n",
    "        print(\"Enrollment failed, exiting.\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Load verification model\n",
    "    model = SpeakerRecognition.from_hparams(\n",
    "        source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "        savedir=MODEL_PATH\n",
    "    )\n",
    "\n",
    "    # Step 3: List of your test audio files\n",
    "    test_files = [f\"v{i}.wav\" for i in range(1, 11)]\n",
    "\n",
    "    # Step 4: Verify enrollment voice against all test audio files\n",
    "    for test_file in test_files:\n",
    "        if not os.path.exists(test_file):\n",
    "            print(f\"Test file '{test_file}' not found, skipping.\")\n",
    "            continue\n",
    "        verify_files(model, ENROLLMENT_AUDIO_FILE, test_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9ec5f81-943c-4ab8-a167-a264ceffd6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores and matches:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing v1.wav with v1.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v1.wav with v2.wav: Similarity Score = 0.1279, Match = No\n",
      "Comparing v1.wav with v3.wav: Similarity Score = 0.0056, Match = No\n",
      "Comparing v1.wav with v4.wav: Similarity Score = -0.0206, Match = No\n",
      "Comparing v1.wav with v5.wav: Similarity Score = 0.1170, Match = No\n",
      "Comparing v1.wav with v6.wav: Similarity Score = 0.1304, Match = No\n",
      "Comparing v1.wav with v7.wav: Similarity Score = 0.1470, Match = No\n",
      "Comparing v1.wav with v8.wav: Similarity Score = 0.1142, Match = No\n",
      "Comparing v1.wav with v9.wav: Similarity Score = 0.0515, Match = No\n",
      "Comparing v1.wav with v10.wav: Similarity Score = 0.1420, Match = No\n",
      "Comparing v2.wav with v1.wav: Similarity Score = 0.1279, Match = No\n",
      "Comparing v2.wav with v2.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v2.wav with v3.wav: Similarity Score = 0.3496, Match = No\n",
      "Comparing v2.wav with v4.wav: Similarity Score = -0.0428, Match = No\n",
      "Comparing v2.wav with v5.wav: Similarity Score = 0.0243, Match = No\n",
      "Comparing v2.wav with v6.wav: Similarity Score = 0.1110, Match = No\n",
      "Comparing v2.wav with v7.wav: Similarity Score = 0.0407, Match = No\n",
      "Comparing v2.wav with v8.wav: Similarity Score = -0.0122, Match = No\n",
      "Comparing v2.wav with v9.wav: Similarity Score = -0.0144, Match = No\n",
      "Comparing v2.wav with v10.wav: Similarity Score = 0.0283, Match = No\n",
      "Comparing v3.wav with v1.wav: Similarity Score = 0.0056, Match = No\n",
      "Comparing v3.wav with v2.wav: Similarity Score = 0.3496, Match = No\n",
      "Comparing v3.wav with v3.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v3.wav with v4.wav: Similarity Score = 0.0191, Match = No\n",
      "Comparing v3.wav with v5.wav: Similarity Score = 0.1119, Match = No\n",
      "Comparing v3.wav with v6.wav: Similarity Score = 0.0663, Match = No\n",
      "Comparing v3.wav with v7.wav: Similarity Score = 0.0462, Match = No\n",
      "Comparing v3.wav with v8.wav: Similarity Score = 0.0004, Match = No\n",
      "Comparing v3.wav with v9.wav: Similarity Score = 0.0900, Match = No\n",
      "Comparing v3.wav with v10.wav: Similarity Score = -0.0006, Match = No\n",
      "Comparing v4.wav with v1.wav: Similarity Score = -0.0206, Match = No\n",
      "Comparing v4.wav with v2.wav: Similarity Score = -0.0428, Match = No\n",
      "Comparing v4.wav with v3.wav: Similarity Score = 0.0191, Match = No\n",
      "Comparing v4.wav with v4.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v4.wav with v5.wav: Similarity Score = -0.0763, Match = No\n",
      "Comparing v4.wav with v6.wav: Similarity Score = 0.0859, Match = No\n",
      "Comparing v4.wav with v7.wav: Similarity Score = 0.1158, Match = No\n",
      "Comparing v4.wav with v8.wav: Similarity Score = -0.0903, Match = No\n",
      "Comparing v4.wav with v9.wav: Similarity Score = 0.1988, Match = No\n",
      "Comparing v4.wav with v10.wav: Similarity Score = -0.0501, Match = No\n",
      "Comparing v5.wav with v1.wav: Similarity Score = 0.1170, Match = No\n",
      "Comparing v5.wav with v2.wav: Similarity Score = 0.0243, Match = No\n",
      "Comparing v5.wav with v3.wav: Similarity Score = 0.1119, Match = No\n",
      "Comparing v5.wav with v4.wav: Similarity Score = -0.0763, Match = No\n",
      "Comparing v5.wav with v5.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v5.wav with v6.wav: Similarity Score = -0.0159, Match = No\n",
      "Comparing v5.wav with v7.wav: Similarity Score = 0.1128, Match = No\n",
      "Comparing v5.wav with v8.wav: Similarity Score = 0.2075, Match = No\n",
      "Comparing v5.wav with v9.wav: Similarity Score = 0.1713, Match = No\n",
      "Comparing v5.wav with v10.wav: Similarity Score = 0.2470, Match = No\n",
      "Comparing v6.wav with v1.wav: Similarity Score = 0.1304, Match = No\n",
      "Comparing v6.wav with v2.wav: Similarity Score = 0.1110, Match = No\n",
      "Comparing v6.wav with v3.wav: Similarity Score = 0.0663, Match = No\n",
      "Comparing v6.wav with v4.wav: Similarity Score = 0.0859, Match = No\n",
      "Comparing v6.wav with v5.wav: Similarity Score = -0.0159, Match = No\n",
      "Comparing v6.wav with v6.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v6.wav with v7.wav: Similarity Score = 0.1102, Match = No\n",
      "Comparing v6.wav with v8.wav: Similarity Score = 0.0781, Match = No\n",
      "Comparing v6.wav with v9.wav: Similarity Score = 0.0944, Match = No\n",
      "Comparing v6.wav with v10.wav: Similarity Score = 0.0704, Match = No\n",
      "Comparing v7.wav with v1.wav: Similarity Score = 0.1470, Match = No\n",
      "Comparing v7.wav with v2.wav: Similarity Score = 0.0407, Match = No\n",
      "Comparing v7.wav with v3.wav: Similarity Score = 0.0462, Match = No\n",
      "Comparing v7.wav with v4.wav: Similarity Score = 0.1158, Match = No\n",
      "Comparing v7.wav with v5.wav: Similarity Score = 0.1128, Match = No\n",
      "Comparing v7.wav with v6.wav: Similarity Score = 0.1102, Match = No\n",
      "Comparing v7.wav with v7.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v7.wav with v8.wav: Similarity Score = 0.1561, Match = No\n",
      "Comparing v7.wav with v9.wav: Similarity Score = 0.3273, Match = No\n",
      "Comparing v7.wav with v10.wav: Similarity Score = 0.1920, Match = No\n",
      "Comparing v8.wav with v1.wav: Similarity Score = 0.1142, Match = No\n",
      "Comparing v8.wav with v2.wav: Similarity Score = -0.0122, Match = No\n",
      "Comparing v8.wav with v3.wav: Similarity Score = 0.0004, Match = No\n",
      "Comparing v8.wav with v4.wav: Similarity Score = -0.0903, Match = No\n",
      "Comparing v8.wav with v5.wav: Similarity Score = 0.2075, Match = No\n",
      "Comparing v8.wav with v6.wav: Similarity Score = 0.0781, Match = No\n",
      "Comparing v8.wav with v7.wav: Similarity Score = 0.1561, Match = No\n",
      "Comparing v8.wav with v8.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v8.wav with v9.wav: Similarity Score = 0.0619, Match = No\n",
      "Comparing v8.wav with v10.wav: Similarity Score = 0.8468, Match = Yes\n",
      "Comparing v9.wav with v1.wav: Similarity Score = 0.0515, Match = No\n",
      "Comparing v9.wav with v2.wav: Similarity Score = -0.0144, Match = No\n",
      "Comparing v9.wav with v3.wav: Similarity Score = 0.0900, Match = No\n",
      "Comparing v9.wav with v4.wav: Similarity Score = 0.1988, Match = No\n",
      "Comparing v9.wav with v5.wav: Similarity Score = 0.1713, Match = No\n",
      "Comparing v9.wav with v6.wav: Similarity Score = 0.0944, Match = No\n",
      "Comparing v9.wav with v7.wav: Similarity Score = 0.3273, Match = No\n",
      "Comparing v9.wav with v8.wav: Similarity Score = 0.0619, Match = No\n",
      "Comparing v9.wav with v9.wav: Similarity Score = 1.0000, Match = Yes\n",
      "Comparing v9.wav with v10.wav: Similarity Score = 0.0723, Match = No\n",
      "Comparing v10.wav with v1.wav: Similarity Score = 0.1420, Match = No\n",
      "Comparing v10.wav with v2.wav: Similarity Score = 0.0283, Match = No\n",
      "Comparing v10.wav with v3.wav: Similarity Score = -0.0006, Match = No\n",
      "Comparing v10.wav with v4.wav: Similarity Score = -0.0501, Match = No\n",
      "Comparing v10.wav with v5.wav: Similarity Score = 0.2470, Match = No\n",
      "Comparing v10.wav with v6.wav: Similarity Score = 0.0704, Match = No\n",
      "Comparing v10.wav with v7.wav: Similarity Score = 0.1920, Match = No\n",
      "Comparing v10.wav with v8.wav: Similarity Score = 0.8468, Match = Yes\n",
      "Comparing v10.wav with v9.wav: Similarity Score = 0.0723, Match = No\n",
      "Comparing v10.wav with v10.wav: Similarity Score = 1.0000, Match = Yes\n",
      "\n",
      "Confusion Matrix:\n",
      "[[88  2]\n",
      " [ 0 10]]\n",
      "\n",
      "Accuracy:  0.9800\n",
      "Precision: 0.8333\n",
      "Recall:    1.0000\n",
      "F1 Score:  0.9091\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.inference import SpeakerRecognition\n",
    "from speechbrain.utils.fetching import LocalStrategy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load model with copy strategy to avoid Windows symlink error\n",
    "model = SpeakerRecognition.from_hparams(\n",
    "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    savedir=\"pretrained_models/spkrec-ecapa-voxceleb\",\n",
    "    local_strategy=LocalStrategy.COPY\n",
    ")\n",
    "\n",
    "# List of audio files\n",
    "audio_files = [f\"v{i}.wav\" for i in range(1, 11)]\n",
    "\n",
    "# Threshold to decide match (can be adjusted based on use case)\n",
    "threshold = 0.75\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "similarity_scores = []\n",
    "\n",
    "print(\"Similarity scores and matches:\")\n",
    "\n",
    "for i, ref_file in enumerate(audio_files):\n",
    "    for j, test_file in enumerate(audio_files):\n",
    "        score, prediction = model.verify_files(ref_file, test_file)\n",
    "        similarity_scores.append(score.item())\n",
    "        \n",
    "        # Ground truth: match if same file index\n",
    "        true_match = 1 if i == j else 0\n",
    "        y_true.append(true_match)\n",
    "        \n",
    "        # Prediction based on threshold on similarity score\n",
    "        pred_match = 1 if score >= threshold else 0\n",
    "        y_pred.append(pred_match)\n",
    "        \n",
    "        print(f\"Comparing {ref_file} with {test_file}: Similarity Score = {score.item():.4f}, Match = {'Yes' if pred_match else 'No'}\")\n",
    "\n",
    "# Calculate confusion matrix and metrics\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5ca350-a037-49b3-a527-34a529326200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENROLLMENT (as 'alexa') ===\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter, then speak for 7 seconds for enrollment... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listening for speech...\n",
      "[16:42:27] Recorded audio for 6.76 seconds.\n",
      "[16:42:27] Wrote WAV file 'alexa.wav' in 0.00 seconds.\n",
      "[16:42:28] Extracted embedding from 'alexa.wav' in 0.66 seconds.\n",
      "[16:42:28] Saved embedding 'alexa.npy' in 0.00 seconds.\n",
      "Enrollment completed and saved as 'alexa.wav' and 'alexa.npy'.\n",
      "\n",
      "=== TESTING (as 'siri') ===\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter, then speak for 7 seconds for verification... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listening for speech...\n",
      "[16:42:42] Recorded audio for 7.08 seconds.\n",
      "[16:42:42] Wrote WAV file 'siri.wav' in 0.00 seconds.\n",
      "[16:42:43] Extracted embedding from 'siri.wav' in 0.69 seconds.\n",
      "[16:42:43] Saved embedding 'siri.npy' in 0.00 seconds.\n",
      "Test completed and saved as 'siri.wav' and 'siri.npy'.\n",
      "[16:42:43] Loaded embedding 'alexa.npy' in 0.01 seconds.\n",
      "[16:42:43] Loaded embedding 'siri.npy' in 0.01 seconds.\n",
      "[16:42:43] Similarity score: 0.7105 (computed in 0.0000s)\n",
      "Speaker verified: same person detected.\n"
     ]
    }
   ],
   "source": [
    "# Comparing Audio files with .npy file\n",
    "\n",
    "import os\n",
    "import time\n",
    "import wave\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "import torchaudio\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "MODEL_PATH = \"pretrained_models/spkrec-ecapa-voxceleb\"\n",
    "ENROLL_AUDIO_FILE = \"alexa.wav\"\n",
    "ENROLL_EMBEDDING_FILE = \"alexa.npy\"\n",
    "TEST_AUDIO_FILE = \"siri.wav\"\n",
    "TEST_EMBEDDING_FILE = \"siri.npy\"\n",
    "AUDIO_FS = 16000\n",
    "CHANNELS = 1\n",
    "FRAME_DURATION_MS = 30\n",
    "MAX_SILENCE_DURATION_SEC = 1.0\n",
    "ENROLL_DURATION = 7  # seconds\n",
    "TEST_DURATION = 7  # seconds\n",
    "THRESHOLD = 0.6  # similarity threshold\n",
    "\n",
    "def write_wave(path, audio_bytes, sample_rate):\n",
    "    start = time.time()\n",
    "    with wave.open(path, \"wb\") as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio_bytes)\n",
    "    end = time.time()\n",
    "    print(f\"[{time.strftime('%X')}] Wrote WAV file '{path}' in {end - start:.2f} seconds.\")\n",
    "\n",
    "def record_audio_vad(duration_limit=10):\n",
    "    vad = webrtcvad.Vad(2)\n",
    "    frame_size = int(AUDIO_FS * FRAME_DURATION_MS / 1000)\n",
    "    silence_frames = 0\n",
    "    voiced_frames = bytearray()\n",
    "    print(\"\\nListening for speech...\")\n",
    "    stream = sd.InputStream(samplerate=AUDIO_FS, channels=CHANNELS, dtype=\"int16\")\n",
    "    stream.start()\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        while True:\n",
    "            frame, _ = stream.read(frame_size)\n",
    "            frame_bytes = frame.tobytes()\n",
    "            is_speech = vad.is_speech(frame_bytes, AUDIO_FS)\n",
    "            if is_speech:\n",
    "                voiced_frames.extend(frame_bytes)\n",
    "                silence_frames = 0\n",
    "            else:\n",
    "                if voiced_frames:\n",
    "                    silence_frames += 1\n",
    "                    if silence_frames * FRAME_DURATION_MS / 1000 > MAX_SILENCE_DURATION_SEC:\n",
    "                        break\n",
    "            if time.time() - start_time > duration_limit:\n",
    "                break\n",
    "    finally:\n",
    "        stream.stop()\n",
    "        stream.close()\n",
    "    end_time = time.time()\n",
    "    print(f\"[{time.strftime('%X')}] Recorded audio for {end_time - start_time:.2f} seconds.\")\n",
    "    if not voiced_frames:\n",
    "        print(\"No speech detected.\")\n",
    "        return None\n",
    "    return bytes(voiced_frames)\n",
    "\n",
    "def wav_to_embedding(model, wav_path):\n",
    "    start = time.time()\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    if sr != AUDIO_FS:\n",
    "        wav = torchaudio.transforms.Resample(sr, AUDIO_FS)(wav)\n",
    "    if wav.size(0) > 1:\n",
    "        wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "    with torch.no_grad():\n",
    "        embedding = model.encode_batch(wav)\n",
    "    embedding_np = embedding.squeeze().cpu().numpy()\n",
    "    end = time.time()\n",
    "    print(f\"[{time.strftime('%X')}] Extracted embedding from '{wav_path}' in {end - start:.2f} seconds.\")\n",
    "    return embedding_np\n",
    "\n",
    "def save_embedding(embedding, path):\n",
    "    start = time.time()\n",
    "    np.save(path, embedding)\n",
    "    end = time.time()\n",
    "    print(f\"[{time.strftime('%X')}] Saved embedding '{path}' in {end - start:.2f} seconds.\")\n",
    "\n",
    "def load_embedding(path):\n",
    "    start = time.time()\n",
    "    if os.path.exists(path):\n",
    "        embedding = np.load(path)\n",
    "        end = time.time()\n",
    "        print(f\"[{time.strftime('%X')}] Loaded embedding '{path}' in {end - start:.2f} seconds.\")\n",
    "        return embedding\n",
    "    end = time.time()\n",
    "    print(f\"[{time.strftime('%X')}] Failed to load embedding '{path}' (file missing). Took {end - start:.2f} seconds.\")\n",
    "    return None\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def enroll_owner(model):\n",
    "    print(\"=== ENROLLMENT (as 'alexa') ===\")\n",
    "    input(f\"Press Enter, then speak for {ENROLL_DURATION} seconds for enrollment...\")\n",
    "    audio_bytes = record_audio_vad(duration_limit=ENROLL_DURATION)\n",
    "    if not audio_bytes:\n",
    "        print(\"No speech detected during enrollment.\")\n",
    "        return False\n",
    "    write_wave(ENROLL_AUDIO_FILE, audio_bytes, AUDIO_FS)\n",
    "    emb = wav_to_embedding(model, ENROLL_AUDIO_FILE)\n",
    "    save_embedding(emb, ENROLL_EMBEDDING_FILE)\n",
    "    print(\"Enrollment completed and saved as 'alexa.wav' and 'alexa.npy'.\")\n",
    "    return True\n",
    "\n",
    "def test_speaker(model):\n",
    "    print(\"\\n=== TESTING (as 'siri') ===\")\n",
    "    input(f\"Press Enter, then speak for {TEST_DURATION} seconds for verification...\")\n",
    "    audio_bytes = record_audio_vad(duration_limit=TEST_DURATION)\n",
    "    if not audio_bytes:\n",
    "        print(\"No speech detected during test.\")\n",
    "        return False\n",
    "    write_wave(TEST_AUDIO_FILE, audio_bytes, AUDIO_FS)\n",
    "    emb = wav_to_embedding(model, TEST_AUDIO_FILE)\n",
    "    save_embedding(emb, TEST_EMBEDDING_FILE)\n",
    "    print(\"Test completed and saved as 'siri.wav' and 'siri.npy'.\")\n",
    "    return True\n",
    "\n",
    "def verify_embeddings():\n",
    "    enroll_emb = load_embedding(ENROLL_EMBEDDING_FILE)\n",
    "    test_emb = load_embedding(TEST_EMBEDDING_FILE)\n",
    "    if enroll_emb is None or test_emb is None:\n",
    "        print(\"Cannot verify without both enrollment and test embeddings.\")\n",
    "        return False\n",
    "    start = time.time()\n",
    "    similarity = cosine_similarity(enroll_emb, test_emb)\n",
    "    end = time.time()\n",
    "    print(f\"[{time.strftime('%X')}] Similarity score: {similarity:.4f} (computed in {end - start:.4f}s)\")\n",
    "    if similarity >= THRESHOLD:\n",
    "        print(\"Speaker verified: same person detected.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Speaker not verified: different person detected.\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    model = EncoderClassifier.from_hparams(\n",
    "        source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "        savedir=MODEL_PATH,\n",
    "    )\n",
    "    if not enroll_owner(model):\n",
    "        return\n",
    "    if not test_speaker(model):\n",
    "        return\n",
    "    verify_embeddings()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4325cf-98d5-47b8-8967-ceb4347a6752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
