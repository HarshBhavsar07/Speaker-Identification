{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768e029a-8761-4159-b9df-fa296c0387cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENROLLMENT (as 'alexa') ===\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press Enter and speak for 5 seconds for enrollment... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 5 seconds...\n",
      "[16:57:27] Saved WAV file 'alexa.wav'.\n",
      "[16:57:27] Extracted embedding from 'alexa.wav'.\n",
      "[16:57:27] Saved embedding 'alexa.npy'.\n",
      "Enrollment completed.\n",
      "[16:57:27] Loaded embedding 'alexa.npy'.\n",
      "\n",
      "=== LIVE VERIFICATION STARTED ===\n",
      "Microphone is active. Say something... (Press Ctrl+C to stop)\n",
      "[16:57:31] Saved WAV file 'temp_live.wav'.\n",
      "[16:57:31] Extracted embedding from 'temp_live.wav'.\n",
      "[16:57:31] Similarity score: 0.6646\n",
      "Speaker verified. Mic remains ON.\n",
      "[16:57:34] Saved WAV file 'temp_live.wav'.\n",
      "[16:57:34] Extracted embedding from 'temp_live.wav'.\n",
      "[16:57:34] Similarity score: 0.6364\n",
      "Speaker verified. Mic remains ON.\n",
      "[16:57:37] Saved WAV file 'temp_live.wav'.\n",
      "[16:57:37] Extracted embedding from 'temp_live.wav'.\n",
      "[16:57:37] Similarity score: 0.4682\n",
      "Speaker NOT verified. Turning microphone OFF.\n",
      "Microphone turned off. Program ended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter and speak for 5 seconds for enrollment... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 5 seconds...\n",
      "[11:51:32] Saved WAV file 'alexa.wav'.\n",
      "[11:51:32] Extracted embedding from 'alexa.wav'.\n",
      "[11:51:32] Saved embedding 'alexa.npy'.\n",
      "Enrollment completed.\n",
      "[11:51:32] Loaded embedding 'alexa.npy'.\n",
      "\n",
      "=== LIVE VERIFICATION STARTED ===\n",
      "Microphone is active. Say something... (Press Ctrl+C to stop)\n",
      "[11:51:35] Saved WAV file 'temp_live.wav'.\n",
      "[11:51:36] Extracted embedding from 'temp_live.wav'.\n",
      "[11:51:36] Similarity score: 0.5038\n",
      "Speaker NOT verified. Turning microphone OFF.\n",
      "Microphone turned off. Program ended.\n"
     ]
    }
   ],
   "source": [
    "# CONTINOUSLY CHECK WEATHER SPEAKER IS IDENTIFIED OF NOT\n",
    "\n",
    "import os\n",
    "import time\n",
    "import wave\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from silero_vad import load_silero_vad, get_speech_timestamps\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "MODEL_PATH = \"pretrained_models/spkrec-ecapa-voxceleb\"\n",
    "ENROLL_AUDIO_FILE = \"alexa.wav\"\n",
    "ENROLL_EMBEDDING_FILE = \"alexa.npy\"\n",
    "AUDIO_FS = 16000\n",
    "CHANNELS = 1\n",
    "ENROLL_DURATION = 5  # seconds to record enrollment audio\n",
    "MIN_FLUENT_ENROLL = 3.0  # minimum fluent speech seconds required for enrollment\n",
    "THRESHOLD = 0.6\n",
    "\n",
    "# Load Silero VAD model globally once\n",
    "vad_model = load_silero_vad()\n",
    "\n",
    "def save_wav(path, audio_np, sample_rate=AUDIO_FS):\n",
    "    audio_int16 = (audio_np * 32767).astype(np.int16)\n",
    "    with wave.open(path, \"wb\") as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(2)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio_int16.tobytes())\n",
    "    print(f\"[{time.strftime('%X')}] Saved WAV file '{path}'.\")\n",
    "\n",
    "def record_audio(duration):\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "    recording = sd.rec(int(duration * AUDIO_FS), samplerate=AUDIO_FS, channels=CHANNELS, dtype=\"float32\")\n",
    "    sd.wait()\n",
    "    return recording.flatten()\n",
    "\n",
    "def detect_longest_fluent_segment(audio_np):\n",
    "    audio_tensor = torch.from_numpy(audio_np)\n",
    "    speech_timestamps = get_speech_timestamps(audio_tensor, vad_model, sampling_rate=AUDIO_FS)\n",
    "    if not speech_timestamps:\n",
    "        return 0, None\n",
    "    longest = max(speech_timestamps, key=lambda seg: seg['end'] - seg['start'])\n",
    "    duration = (longest['end'] - longest['start']) / AUDIO_FS\n",
    "    segment_audio = audio_np[longest['start']:longest['end']]\n",
    "    return duration, segment_audio\n",
    "\n",
    "def wav_to_embedding(model, wav_path):\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    if sr != AUDIO_FS:\n",
    "        wav = torchaudio.transforms.Resample(sr, AUDIO_FS)(wav)\n",
    "    if wav.size(0) > 1:\n",
    "        wav = torch.mean(wav, dim=0, keepdim=True)\n",
    "    with torch.no_grad():\n",
    "        emb = model.encode_batch(wav)\n",
    "    emb_np = emb.squeeze().cpu().numpy()\n",
    "    print(f\"[{time.strftime('%X')}] Extracted embedding from '{wav_path}'.\")\n",
    "    return emb_np\n",
    "\n",
    "def save_embedding(embedding, path):\n",
    "    np.save(path, embedding)\n",
    "    print(f\"[{time.strftime('%X')}] Saved embedding '{path}'.\")\n",
    "\n",
    "def load_embedding(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[{time.strftime('%X')}] Embedding file '{path}' not found.\")\n",
    "        return None\n",
    "    emb = np.load(path)\n",
    "    print(f\"[{time.strftime('%X')}] Loaded embedding '{path}'.\")\n",
    "    return emb\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def enroll_owner(model):\n",
    "    print(\"=== ENROLLMENT (as 'alexa') ===\")\n",
    "    while True:\n",
    "        input(f\"Press Enter and speak for {ENROLL_DURATION} seconds for enrollment...\")\n",
    "        audio_np = record_audio(ENROLL_DURATION)\n",
    "        dur, fluent_audio = detect_longest_fluent_segment(audio_np)\n",
    "        if fluent_audio is None or dur < MIN_FLUENT_ENROLL:\n",
    "            print(f\"Fluent speech duration {dur:.2f}s too short. Please try again.\")\n",
    "        else:\n",
    "            save_wav(ENROLL_AUDIO_FILE, fluent_audio)\n",
    "            emb = wav_to_embedding(model, ENROLL_AUDIO_FILE)\n",
    "            save_embedding(emb, ENROLL_EMBEDDING_FILE)\n",
    "            print(\"Enrollment completed.\")\n",
    "            return True\n",
    "\n",
    "def live_verification_loop(model, enrolled_emb):\n",
    "    global mic_active\n",
    "    mic_active = True\n",
    "    print(\"\\n=== LIVE VERIFICATION STARTED ===\")\n",
    "    print(\"Microphone is active. Say something... (Press Ctrl+C to stop)\")\n",
    "    buffer_duration = 3.0  # seconds of audio per verification chunk\n",
    "    buffer_size = int(buffer_duration * AUDIO_FS)\n",
    "    audio_buffer = np.zeros(buffer_size, dtype=np.float32)\n",
    "    idx = 0\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=AUDIO_FS, channels=CHANNELS, dtype=\"float32\") as stream:\n",
    "            while mic_active:\n",
    "                data, _ = stream.read(int(AUDIO_FS * 0.5))  # read half-second\n",
    "                chunk = data.flatten()\n",
    "                length = len(chunk)\n",
    "                if idx + length > buffer_size:\n",
    "                    shift = idx + length - buffer_size\n",
    "                    audio_buffer[:buffer_size-shift] = audio_buffer[shift:idx]\n",
    "                    idx -= shift\n",
    "                audio_buffer[idx:idx+length] = chunk\n",
    "                idx += length\n",
    "                if idx >= buffer_size:\n",
    "                    dur, speech_segment = detect_longest_fluent_segment(audio_buffer)\n",
    "                    if speech_segment is not None and dur >= 1.0:\n",
    "                        temp_path = \"temp_live.wav\"\n",
    "                        save_wav(temp_path, speech_segment)\n",
    "                        live_emb = wav_to_embedding(model, temp_path)\n",
    "                        similarity = cosine_similarity(enrolled_emb, live_emb)\n",
    "                        print(f\"[{time.strftime('%X')}] Similarity score: {similarity:.4f}\")\n",
    "                        if similarity >= THRESHOLD:\n",
    "                            print(\"Speaker verified. Mic remains ON.\")\n",
    "                        else:\n",
    "                            print(\"Speaker NOT verified. Turning microphone OFF.\")\n",
    "                            mic_active = False\n",
    "                            break\n",
    "                    idx = 0\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nUser interrupted, stopping microphone.\")\n",
    "        mic_active = False\n",
    "\n",
    "def main():\n",
    "    model = EncoderClassifier.from_hparams(\n",
    "        source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "        savedir=MODEL_PATH\n",
    "    )\n",
    "    if not enroll_owner(model):\n",
    "        return\n",
    "    enrolled_emb = load_embedding(ENROLL_EMBEDDING_FILE)\n",
    "    if enrolled_emb is None:\n",
    "        print(\"Enrollment embedding missing, exiting.\")\n",
    "        return\n",
    "    live_verification_loop(model, enrolled_emb)\n",
    "    print(\"Microphone turned off. Program ended.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045213c-59a7-4c2d-b673-86f4b12e67b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
