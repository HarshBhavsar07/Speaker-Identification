{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeea203-5e38-41aa-824a-8dac227f7760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up model...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "=== ENROLLMENT ===\n",
      "Press Enter, then speak your enrollment phrase for 5 seconds (quiet background recommended). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluent speech not detected or too short, please try again.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "=== ENROLLMENT ===\n",
      "Press Enter, then speak your enrollment phrase for 5 seconds (quiet background recommended). \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrollment complete.\n",
      "Voiceprint registered.\n",
      "=== LIVE VERIFICATION STARTED ===\n",
      "Microphone is now always-on for speaker verification.\n",
      "(Warning) Verification took longer than 100 ms.\n",
      "(Warning) Verification took longer than 100 ms.\n",
      "(Warning) Verification took longer than 100 ms.\n",
      "Hi, how can I help you?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import torch\n",
    "import threading\n",
    "import time\n",
    "import queue\n",
    "from silero_vad import load_silero_vad, get_speech_timestamps\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "\n",
    "# Constants\n",
    "AUDIO_FS = 16000\n",
    "CHANNELS = 1\n",
    "SLIDING_WINDOW_SECONDS = 1.5\n",
    "STEP_SIZE_SECONDS = 0.75\n",
    "BUFFER_SIZE_SECONDS = 20\n",
    "MIN_SPEAK_TIME_ENROLL = 3.0\n",
    "MAX_SPEAK_TIME_ENROLL = 5.0\n",
    "MIN_SPEAK_TIME_VERIFY = 1.5\n",
    "SIMILARITY_THRESHOLD = 0.6\n",
    "CONSECUTIVE_MATCHES_REQUIRED = 3\n",
    "\n",
    "vad_model = load_silero_vad()\n",
    "spkrec_model = EncoderClassifier.from_hparams(\n",
    "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
    ")\n",
    "\n",
    "audio_queue = queue.Queue()\n",
    "stop_event = threading.Event()\n",
    "mic_active = threading.Event()\n",
    "\n",
    "\n",
    "def extract_embedding(audio):\n",
    "    audio = audio / (np.max(np.abs(audio)) + 1e-10)\n",
    "    tensor = torch.from_numpy(audio.astype(np.float32).reshape(1, -1))\n",
    "    with torch.no_grad():\n",
    "        emb = spkrec_model.encode_batch(tensor)\n",
    "    emb = emb.squeeze()\n",
    "    emb /= emb.norm(p=2)\n",
    "    return emb.cpu().numpy()\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    a_norm = a / np.linalg.norm(a)\n",
    "    b_norm = b / np.linalg.norm(b)\n",
    "    return float(np.dot(a_norm, b_norm))\n",
    "\n",
    "\n",
    "def detect_fluent_speech(audio_np):\n",
    "    audio_tensor = torch.from_numpy(audio_np.astype(np.float32))\n",
    "    speech_segments = get_speech_timestamps(audio_tensor, vad_model, sampling_rate=AUDIO_FS)\n",
    "    if not speech_segments:\n",
    "        return 0, None\n",
    "    longest_segment = max(speech_segments, key=lambda s: s['end'] - s['start'])\n",
    "    start, end = longest_segment['start'], longest_segment['end']\n",
    "    duration = (end - start) / AUDIO_FS\n",
    "    return duration, audio_np[start:end]\n",
    "\n",
    "\n",
    "def record_fixed_duration(duration, prompt=\"\"):\n",
    "    if prompt:\n",
    "        print(prompt)\n",
    "    audio = sd.rec(int(duration * AUDIO_FS), samplerate=AUDIO_FS, channels=CHANNELS, dtype='float32')\n",
    "    sd.wait()\n",
    "    return audio.flatten()\n",
    "\n",
    "\n",
    "def audio_callback(indata, frames, time_info, status):\n",
    "    if status:\n",
    "        pass\n",
    "    audio_queue.put(indata[:, 0].copy())\n",
    "\n",
    "\n",
    "def verification_worker(enrolled_embedding):\n",
    "    buffer = np.zeros(int(BUFFER_SIZE_SECONDS * AUDIO_FS), dtype=np.float32)\n",
    "    buffer_len = 0\n",
    "    window_size = int(SLIDING_WINDOW_SECONDS * AUDIO_FS)\n",
    "    step_size = int(STEP_SIZE_SECONDS * AUDIO_FS)\n",
    "    consecutive_matches = 0\n",
    "    greeted = False\n",
    "    live_verification_started_printed = False\n",
    "\n",
    "    while not stop_event.is_set():\n",
    "        try:\n",
    "            chunk = audio_queue.get(timeout=0.1)\n",
    "        except queue.Empty:\n",
    "            continue\n",
    "\n",
    "        if not live_verification_started_printed:\n",
    "            print(\"=== LIVE VERIFICATION STARTED ===\")\n",
    "            print(\"Microphone is now always-on for speaker verification.\")\n",
    "            live_verification_started_printed = True\n",
    "\n",
    "        chunk_len = len(chunk)\n",
    "        if buffer_len + chunk_len > len(buffer):\n",
    "            overflow = buffer_len + chunk_len - len(buffer)\n",
    "            buffer[:len(buffer) - chunk_len] = buffer[overflow:buffer_len]\n",
    "            buffer_len -= overflow\n",
    "\n",
    "        buffer[buffer_len:buffer_len + chunk_len] = chunk\n",
    "        buffer_len += chunk_len\n",
    "\n",
    "        if buffer_len >= window_size and mic_active.is_set():\n",
    "            for start_idx in range(0, buffer_len - window_size + 1, step_size):\n",
    "                segment = buffer[start_idx:start_idx + window_size]\n",
    "                dur, fluent_audio = detect_fluent_speech(segment)\n",
    "                if dur >= MIN_SPEAK_TIME_VERIFY:\n",
    "                    start_t = time.perf_counter()\n",
    "                    live_emb = extract_embedding(fluent_audio)\n",
    "                    similarity = cosine_similarity(enrolled_embedding, live_emb)\n",
    "                    elapsed_ms = (time.perf_counter() - start_t) * 1000\n",
    "\n",
    "                    # internal efficiency warning (optional)\n",
    "                    if elapsed_ms > 100:\n",
    "                        print(\"(Warning) Verification took longer than 100 ms.\")\n",
    "\n",
    "                    if similarity >= SIMILARITY_THRESHOLD:\n",
    "                        consecutive_matches += 1\n",
    "                        if not greeted and consecutive_matches >= CONSECUTIVE_MATCHES_REQUIRED:\n",
    "                            print(\"Hi, how can I help you?\")\n",
    "                            greeted = True\n",
    "                    else:\n",
    "                        print(\"Sorry, I can't reply to you.\")\n",
    "                        mic_active.clear()\n",
    "                        stop_event.set()\n",
    "                        return\n",
    "\n",
    "            buffer[:buffer_len - step_size] = buffer[step_size:buffer_len]\n",
    "            buffer_len -= step_size\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Warming up model...\")\n",
    "    dummy = torch.randn(1, int(SLIDING_WINDOW_SECONDS * AUDIO_FS))\n",
    "    with torch.no_grad():\n",
    "        spkrec_model.encode_batch(dummy)\n",
    "\n",
    "    fluent_audio = None\n",
    "    while fluent_audio is None:\n",
    "        input(\"=== ENROLLMENT ===\\nPress Enter, then speak your enrollment phrase for 5 seconds (quiet background recommended).\")\n",
    "        audio = record_fixed_duration(MAX_SPEAK_TIME_ENROLL)\n",
    "        dur, seg = detect_fluent_speech(audio)\n",
    "        if seg is not None and dur >= MIN_SPEAK_TIME_ENROLL:\n",
    "            fluent_audio = seg\n",
    "        else:\n",
    "            print(\"Fluent speech not detected or too short, please try again.\")\n",
    "\n",
    "    enrolled_embedding = extract_embedding(fluent_audio)\n",
    "\n",
    "    print(\"Enrollment complete.\")\n",
    "    print(\"Voiceprint registered.\")\n",
    "\n",
    "    stop_event.clear()\n",
    "    mic_active.set()\n",
    "\n",
    "    with sd.InputStream(samplerate=AUDIO_FS, channels=CHANNELS, callback=audio_callback, blocksize=1024):\n",
    "        worker = threading.Thread(target=verification_worker, args=(enrolled_embedding,), daemon=True)\n",
    "        worker.start()\n",
    "        try:\n",
    "            while not stop_event.is_set():\n",
    "                time.sleep(0.1)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nExiting on user interrupt.\")\n",
    "            stop_event.set()\n",
    "            mic_active.clear()\n",
    "\n",
    "    print(\"Microphone stopped. Program ended.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b46e73-f7e0-45bb-a2d1-4248d292dc06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
